<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron, Deepak Pathak, Saurabh Gupta and Aditya Kusupati*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 16px;
     font-weight: 400
  }
  heading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 19px;
     font-weight: 1000
  }
  strong {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 16px;
     font-weight: 800
  }
  strongred {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     color: 'red' ;
     font-size: 16px
  }
  sectionheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 22px;
     font-weight: 600
  }
  pageheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 38px;
     font-weight: 400
  }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/W.png"> -->
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Saqib Azim</title>
  <meta name="Saqib Azim's Homepage" http-equiv="Content-Type" content="Saqib Azim's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
     <pageheading>Saqib Azim</pageheading><br>
     <b>email</b>:
     azimsaqib10@gmail.com
     <font id="email" style="display:inline;">
        <noscript><i>Please enable Javascript to view</i></noscript>
     </font>
<!--      <script>
     emailScramble = new scrambledString(document.getElementById('email'),
          'emailScramble', 'aecsukthoad@wssg.iutn.uinp',
          [14,24,10,15,26,1,7,16,21,6,25,9,13,3,11,19,23,17,4,20,22,12,2,8,18,5]);
     </script> -->
  </p>

  <tr>
     <td width="32%" valign="top"><a href="#Bio"><img src="images/saqib.jpg" width="100%" style="border-radius:15px"></a>
     <p align=center>
     <!-- <a href="pubs/CV_SaqibAzim.pdf" target="_blank">CV</a> | <a href="https://scholar.google.com/citations?user=-KK-60AAAAAJ&hl=en" target="_blank">Scholar</a> | <a href="https://github.com/saqib1707" target="_blank">Github</a> <br> -->
     <a href="pubs/CV_SaqibAzim.pdf" target="_blank">CV</a> | <a href="https://github.com/saqib1707" target="_blank">Github</a> <br>
    </p>
     </td>
     <td width="68%" valign="top" align="justify" id="Bio">
     <p> Hello All !! Welcome to my tiny corner on the web. </p>
     <p> Currently, I am an Assistant Researcher at Hitachi Central Research Lab, Tokyo advised by <a href="https://scholar.google.com/citations?user=ZIxQ5zAAAAAJ&hl=en" target="_blank"> Katsuyuki Nakamura </a> and  Takumi Nito. I work on developing support tools for navigation of human workers in dynamic real-world environments.</p>
     <p> My broad research interests currently include Machine Learning, Computer Vision, Robotics, and Signal Processing </p>
     <p> Prior to this, I spent 4 amazing years at IIT Bombay, earning a Bachelor's in EE with a Minor in CS. I was advised by <a href="https://www.ee.iitb.ac.in/wiki/faculty/dc" target="_blank"> Debraj Chakraborty </a> for my bachleor's thesis on optimal pursuer-evader shepherding problem.</p>

     </td>
  </tr>
</table>

<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td id="Preprints"> <sectionheading>&nbsp;&nbsp;Preprints</sectionheading></td></tr>
</table> -->

<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="33%" valign="top" align="center"><a href="pubs/pal.pdf" target="_blank"><img src="images/pal.PNG" alt="PAL" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="pubs/pal.pdf" target="_blank" id="pal">
        <heading>PAL: Pretext-based Active Learning</heading></a><br>
        Shubhang Bhatnagar, <strong>Sachin Goyal</strong>*, Darshan Tank*, <a href="https://www.ee.iitb.ac.in/~asethi/" target="_blank"> Amit Sethi </a> <br>
        Under Review, CVPR 2021<br>
        </p>

        <div class="paper" id="pal">
        <a href="javascript:toggleblock('palabs')">abstract</a> /
        <a href="https://arxiv.org/pdf/2010.15947.pdf" target="_blank">paper</a>
        <br>

        <p align="justify"> <i id="palabs">The goal of active learning algorithms is to judiciously select subsets of unlabeled samples to be labeled by an oracle, in order to reduce the time and cost associated with supervised learning. Previously, active learning techniques for deep neural networks have used the same network for the task at hand (e.g., classification) as well as sample selection,  which  can  be  conflicting  goals.   To  address  this issue,  we  use  a  separate  sample  scoring  network  to  capture the relevant information about the distribution of the labeled samples,  and use it to assess the novelty of unlabeled samples.  Specifically, we propose to efficiently train the scoring network using a self-supervised learning (pre-text)  task  on  the  labeled  samples.    To  make  the  scoring network more robust, we added to it another head, which is trained using the supervised (task) objective itself.  The scoring network was paired with a scoring function that allows an appropriate trade-off between the two heads.  We also ensure that the selected samples are diverse by selectively fine-tuning the scoring network in sub-rounds of each query round.  The resulting scheme performs competitively with the state-of-the-art on benchmark datasets.  More importantly, in realistic scenarios when some labels are erroneous and new classes are introduced on the fly, the performance of the proposed method remains strong.</i></p>

  </tr>
</table> -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td id="ConfPublications"> <sectionheading>&nbsp;&nbsp;Conference Publications</sectionheading></td></tr>
</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <!-- <tr>
     <td width="33%" valign="top" align="center"><a href="pubs/drocc.pdf" target="_blank"><img src="images/drocc.PNG" alt="DROCC" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="pubs/drocc.pdf" target="_blank" id="drocc">
        <heading>DROCC: Deep Robust One-Class Classification</heading></a><br>
        <strong>Sachin Goyal</strong>, <a href="https://stanford.edu/~aditir/" target="_blank"> Aditi Raghunathan</a>, Moksh Jain, <a href="http://harsha-simhadri.org/" target="_blank"> Harsha Vardhan Simhadri </a>, <a href="https://www.prateekjain.org/" target="_blank"> Prateek Jain </a> <br>
        International Conference on Machine Learning (ICML), 2020<br>
        </p>

        <div class="paper" id="drocc">
        <a href="javascript:toggleblock('droccabs')">abstract</a> /
        <a href="https://proceedings.icml.cc/book/4293.pdf" target="_blank">paper</a> /
        <a href="https://github.com/microsoft/EdgeML" target="_blank">code</a> /
        <a href="https://www.youtube.com/watch?v=20pDzeSgSfw&t=789s" target="_blank">video</a>
        <br>

        <p align="justify"> <i id="droccabs">Classical approaches for one-class problems such as one-class SVM and isolation forest require careful feature engineering when applied to structured domains like images. State-of-the-art methods aim to leverage deep learning to learn appropriate features via two main approaches. The first approach based on predicting transformations (Golan & El-Yaniv, 2018; Hendrycks et al., 2019a) while successful in some domains, crucially depends on an appropriate domain-specific set of transformations that are hard to obtain in general. The second approach of minimizing a classical one-class loss on the learned final layer representations, e.g., DeepSVDD (Ruff et al., 2018) suffers from the fundamental drawback of representation collapse. In this work, we propose Deep Robust One Class Classification (DROCC) that is both applicable to most standard domains without requiring any side-information and robust to representation collapse. DROCC is based on the assumption that the points from the class of interest lie on a well-sampled, locally linear low dimensional manifold. Empirical evaluation demonstrates that DROCC is highly effective in two different one-class problem settings and on a range of real-world datasets across different domains: tabular data, images (CIFAR and ImageNet), audio, and time-series, offering up to 20% increase in accuracy over the state-of-the-art in anomaly detection. DROCC's code is available at <a href="https://github.com/Microsoft/EdgeML/">https://github.com/Microsoft/EdgeML/</a>.</i></p>

  </tr> -->


  <tr>
     <td width="33%" valign="top" align="center"><a href="pubs/lps.pdf" target="_blank"><img src="images/lps.PNG" alt="LPS" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="pubs/lps.pdf" target="_blank" id="lps">
        <heading>Indoor Distance Estimation using LSTMs over WLAN Network</heading></a><br>
        <a href="https://sabsathai.github.io/" target="_blank"> Pranav Sankhe</a>, <strong> Saqib Azim </strong>, <a href="https://saching007.github.io/" target="_blank">Sachin Goyal</a>, Tanya Choudhary,<a href="https://www.ee.iitb.ac.in/~akumar/" target="_blank"> Kumar Appaiah </a>, <a href="https://www.sc.iitb.ac.in/~srikant/dokuwiki/doku.php" target="_blank"> Sukumar Srikant </a> <br>
        India Patent Application 201821047043, filed Dec' 2018. Patent Pending.<br>
        IEEE Workshop on Positioning, Navigation and Communications (WPNC), 2019<br>
        </p>

        <div class="paper" id="lps">
        <a href="javascript:toggleblock('lpsabs')">abstract</a> /
        <a href="https://ieeexplore.ieee.org/abstract/document/8970257" target="_blank">paper</a> /
        <a href="https://arxiv.org/pdf/2003.13991.pdf" target="_blank">arxiv</a> /
        <a href="pubs/HAIC2020_slides.pdf" target="_blank">presentation</a>
        <br>

        <p align="justify"> <i id="lpsabs">The  Global  Navigation  Satellite  Systems  (GNSS)like  GPS  suffer  from  accuracy  degradation  and  are  almost unavailable in indoor environments. Indoor positioning systems(IPS)   based   on   WiFi   signals   have   been   gaining   popularity.However,  owing  to  the  strong  spatial  and  temporal  variationsof  wireless  communication  channels  in  the  indoor  environment,the  achieved  accuracy  of  existing  IPS  is  around  several  tens  ofcentimeters. We present the detailed design and implementationof a self-adaptive WiFi-based indoor distance estimation systemusing  LSTMs.  The  system  is  novel  in  its  method  of  estimatingwith  high  accuracy  the  distance  of  an  object  by  overcomingpossible  causes  of  channel  variations  and  is  self-adaptive  tothe  changing  environmental  and  surrounding  conditions.  Theproposed design has been developed and physically realized overa WiFi network consisting of ESP8266 (NodeMCU) devices. Theexperiments were conducted in a real indoor environment whilechanging the surroundings in order to establish the adaptabilityof  the  system.  We  compare  different  architectures  for  this  taskbased  on  LSTMs,  CNNs,  and  fully  connected  networks  (FCNs).We  show  that  the  LSTM  based  model  performs  better  amongall the above-mentioned architectures by achieving an accuracyof5.85cm  with  a  confidence  interval  of93%on  the  scale  of(8.46m x6.98m). To the best of our knowledge, the proposedmethod outperforms other methods reported in the literature bya  significant  margin.</p>

  </tr>
  
  <!-- <tr>
     <td width="33%" valign="top" align="center"><a href="pubs/spie.pdf" target="_blank"><img src="images/spie.PNG" alt="SPIE" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="pubs/spie.pdf" target="_blank" id="spie">
        <heading>Improving self super resolution in magnetic resonance images</heading></a><br>
        <strong> Sachin Goyal </strong>, Can Zhao,<a href="https://asjog.github.io/" target="_blank"> Amod Jog </a>, Aaron Carass, <a href="https://engineering.jhu.edu/ece/faculty/prince-jerry-l/" target="_blank"> Jerry L. Prince </a> <br>
        SPIE Conference on Medical Imaging and Biomedical Applications, 2018 <br>
        </p>

        <div class="paper" id="spie">
        <a href="javascript:toggleblock('spieabs')">abstract</a> /
        <a href="https://ieeexplore.ieee.org/abstract/document/8970257" target="_blank">paper</a> /
        <a href="https://arxiv.org/pdf/2003.13991.pdf" target="_blank">arxiv</a>
        <br>

        <p align="justify"> <i id="spieabs">Magnetic resonance (MR) images (MRI) are routinely acquired with high in-plane resolution and lower through-plane resolution. Improving the resolution of such data can be achieved through post-processing techniques knows as super-resolution (SR), with various frameworks in existence. Many of these approaches rely on external databases from which SR methods infer relationships between low and high resolution data. The concept of self super-resolution (SSR) has been previously reported, wherein there is no external training data with the method only relying on the acquired image. The approach involves extracting image patches from the acquired image constructing new images based on regression and combining the new images by Fourier Burst Accumulation. In this work, we present four improvements to our previously reported SSR approach. We demonstrate these improvements have a significant effect on improving image quality and the measured resolution.</p>

  </tr>   -->

</table>


<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <br/>
  <tr><td id="Software"><sectionheading>&nbsp;&nbsp;Software</sectionheading></td></tr>
</table> -->
<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top"><a href="https://github.com/microsoft/EdgeML" target="_blank"><img src="images/edgeml.png" alt="EdgeML" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://github.com/microsoft/EdgeML" id="EdgeML" target="_blank">
        <heading>EdgeML: Machine Learning for resource-constrained edge devices</heading></a><br>
        Work of many amazing collaborators. I am one of the current collaborator.<br>  -->
        <!-- <a href="https://dkdennis.xyz/">Don Dennis</a>, <a href="http://www.sridhargopinath.in">Sridhar Gopinath</a>, <a href="https://aigen.github.io/">Chirag Gupta</a>, <a href="https://ashishkumar1993.github.io/">Ashish Kumar</a>, <strong>Aditya Kusupati</strong>, <a href="https://shishirpatil.github.io/">Shishir Patil</a> and <a href="http://harsha-simhadri.org/">Harsha Vardhan Simhadri</a> (&alpha;&beta; ordering)<br> -->
        <!-- Github, Microsoft Research India, 2017-present. -->
        <!-- <br></p>

        <div class="paper" id="edgeml">
        <a href="javascript:toggleblock('edgemlabs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('edgeml')" class="togglebib">bibtex</a>

        <p align="justify"> <i id="edgemlabs">Open source repository for all the research outputs on resource efficient Machine Learning from Microsoft Research India. It contains scalable and multi-framework compatible implementations of Bonsai, ProtoNN, FastCells, EMI-RNN, ShaRNN, RNNPool, DROCC, a tool named SeeDot for fixed-point compilation of ML models along with applications such as on-device Keyword spotting and Gesturepod.</i><br>EdgeML is under MIT license and is open to contributions and suggestions. Please <a shape="rect" href="javascript:togglebib('edgeml')" class="togglebib">cite</a> the software if you happen to use EdgeML in your research or otherwise (use the latest bibtex from the repository in case this gets outdated)</p>

<pre xml:space="preserve"> -->
<!-- @misc{edgeml03,
    author = {{Dennis, Don Kurian and Gaurkar, Yash and 
      Gopinath, Sridhar and Gupta, Chirag and
      Jain, Moksh and Kumar, Ashish and
      Kusupati, Aditya and Lovett, Chris and
      Patil, Shishir Girish and Simhadri, Harsha Vardhan}},
    title = {{EdgeML: Machine Learning 
      for resource-constrained edge devices}},
    url = {https://github.com/Microsoft/EdgeML},
    version = {0.3},
}</pre>
        </div>
     </td>
  </tr>
</table> -->


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td id="Miscellaneous"> <sectionheading>&nbsp;&nbsp;Miscellaneous</sectionheading></td></tr>
</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top" align="center"><a href="edl.html" target="_blank"><img src="images/btp_wallpaper.png" alt="DPAC" width="100%" style="border-radius:15px"></a>
    <td width="67%" valign="top">
       <p><a href="edl.html" target="_blank" id="dpac">
       <heading>Optimal Pursuer-Evader Shepherding Problem</heading></a><br>
       <strong> Saqib Azim </strong>, <a href="https://www.ee.iitb.ac.in/wiki/faculty/dc" target="_blank">Debraj Chakraborty</a> <br>
       Undergraduate Thesis <br>
       </p>

       <div class="paper" id="btpthesis">
        <a href="javascript:toggleblock('btpthesisabs')">abstract</a> /
       <a href="pubs/btp_thesis.pdf" target="_blank">Thesis</a> /
       <a href="pubs/btp_finalPresentation.pdf" target="_blank">Presentation</a>
       <br>

       <p align="justify"> <i id="btpthesisabs"> In this report, we proposed an interaction rule between an evader and a pursuer and our objective
        was to try to find an optimal feedback control for the pursuer to drive the evaders to destination. With
        this regard, we first formulated our problem as a constrained optimization problem and solved using
        global search algorithm available in global optimization toolbox of matlab. The result from these ex-
        periments were then used to predict a feedback control algorithm but unfortunately this could not be
        made possible. Then we shifted from predicting ourselves to let the machine learn from the data and
        predict the trajectory for us. We used LSTM-based model with fully connected layers and posed the
        problem as a regression task to produce pursuer next position given current and past trajectory infor-
        mation of all the agents. The experimental results from the optimization task was used as dataset for
        this approach. After training, the trajectories were estimated iteratively for numerous initial conditions
        but we could not get the desired result. This approach requires modifications in order for it to work.</p>

 </tr>
  <tr>
     <td width="33%" valign="top" align="center"><a href="edl.html" target="_blank"><img src="images/edl_wallpaper.png" alt="DPAC" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="edl.html" target="_blank" id="dpac">
        <heading>PPG Signal Acquisition Module</heading></a><br>
        <strong> Saqib Azim </strong>, Pranav Sankhe, Ritik Madan <br>
        </p>

        <div class="paper" id="edlPPG">
          <a href="javascript:toggleblock('edlPPGabs')">abstract</a> /
        <a href="pubs/EDL_FinalReport.pdf" target="_blank">Technical Report</a>
        <br>

        <p align="justify"> <i id="edlPPGabs"> A photoplethysmogram (PPG) is an optically obtained plethysmogram, a volumetric
          measurement of an organ. With each cardiac cycle the heart pumps blood to the periphery. The
          change in the volume caused by the blood is detected by illuminating the skin with IR light. We
          developed and implemented an electronic system to capture and display the PPG signal. We
          make infrared (IR) light incident on finger tip and measure the reflected IR light using a
          phototransistor which contains the PPG signal. The raw PPG signal is in the form of current
          output of the phototransistor, typically [0.2 - 0.4] mA, and we use a current to voltage converter
          to get the voltage signal. The raw PPG often has a large slowly varying baseline and it needs to
          be restored to optimally use the available ADC range. We carry out baseline restoration by
          controlling the bias voltage of the current injector using a microcontroller. We amplify the
          signal using a fixed value of gain resistor in the current to voltage converter. We also designed
          an auto-led intensity control to control the LED current and hence the emitted IR light in an
          effort to make the acquisition module adaptable to users with varying skin colours, motion
          artifacts etc. Finally we display the PPG signal on an android smartphone by transmitting the
          PPG signal over bluetooth.</p>

  </tr>

  <!-- <tr>
     <td width="33%" valign="top" align="center"><img src="images/graphics.PNG" alt="DPAC" width="90%" style="border-radius:15px">
     <td width="67%" valign="top">
        <p>
        <heading>The Music Box Short Film</heading><br>
        <strong>Sachin Goyal</strong>, Arpan Banerjee <br>
        </p>

        <div class="paper" id="graphics">
        <a href="javascript:toggleblock('graphicsabs')">abstract</a> /
        <a href="https://www.youtube.com/watch?v=DysZUCfkbf0" target="_blank">Video</a>
        <br>

        <p align="justify"> <i id="graphicsabs"> Created an animated film with a music box and two humanoids using hierarchical modelling in OpenGL+. Wrote GLSL shaders to implement Gouraud shading for humanoids and apply textures to room. </p>

  </tr> -->

</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td id="Teaching"><sectionheading>&nbsp;&nbsp;Teaching</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top"><a href="#Teaching"><img src="images/teaching.png" alt="teaching" width="90%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p>
          <b>EE 210: Signals and Systems, Spring '19, IIT Bombay</b><br>
          <!-- <strong>Instructor</strong>: Prof. Supratik Chakraborty<br> -->
        </p>
        <!-- <p>
          <b>Responsible for evaluating and helping UG students </b><br>
          <strong>Instructor</strong>: Prof. Sharat Chandran<br>
        </p> -->
     </td>
  </tr>
</table>

<!-- <table width="100%" align="center" border="0" cellpadding="10">
  <tr><td id="Misc">
     <sectionheading>&nbsp;&nbsp;Misc</sectionheading>
     <ul>
     <li> A short blog on cracking japanese placement interviews <a href="pubs/sony.pdf" target="_blank">here</a> </li>
     </ul>
  </td></tr>
</table> -->

<!-- <a href="http://s01.flagcounter.com/more/oc"><img src="https://s01.flagcounter.com/count2/oc/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     <tr><td><br><p align="right"><font size="2">
     Template: <a href="https://jonbarron.info">this</a>, <a href="https://people.eecs.berkeley.edu/~pathak/">this</a>, <a href="http://saurabhg.web.illinois.edu/">this</a> and <a href="https://homes.cs.washington.edu/~kusupati/">this</a>
     </font></p></td></tr>
</table> -->


  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('spieabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('droccabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('palabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('lpsabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('dpacabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('graphicsabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('edgemlabs');
</script>

</body>

</html>
