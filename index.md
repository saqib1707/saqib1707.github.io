---
layout: page
---
{% include JB/setup %}
<div style="float:right; display: inline-block; position: relative; width: 230px; height: 250px; padding: 5px;">
	<div style="width: 200px; height: 200px; overflow: hidden; border-radius: 50%; margin-left: auto; margin-right: auto;">
		<img style="width: auto; height: 100%;" src="https://avatars0.githubusercontent.com/u/18272074?s=400&u=59209b7d272a1e86a7547e24e29096722a6a0898&v=4">
	</div>
	<div style="width: auto; height: auto; position: absolute; margin-left: 0px; margin-right: 0px; text-align: center; left:0; right:0; bottom: 0">
		<a href="{{site.url}}/assets/CV/CV_SaqibAzim_onepage.pdf"><b>CV</b></a> / <a href="https://github.com/saqib1707"><b>Github</b></a> / <a href="https://www.linkedin.com/in/saqibazim/"><b>LinkedIn</b></a>
	</div>
</div>

<div>
Hey there! I am a second year Masters student at <a href="https://jacobsschool.ucsd.edu/">UC San Diego</a>. I am a student researcher at the <a href="https://contextualrobotics.ucsd.edu/">Contextual Robotics Institute's</a> <a href="http://erl.ucsd.edu/">Existential Robotics Lab</a> working under the supervision of <a href="https://natanaso.github.io/">Prof. Nikolay Atanasov</a>. Previously, I was an assistant researcher in the Intelligent Vision Research Dept. at <a href="https://www.hitachi.com/rd/index.html">Hitachi R&D Japan</a>, advised by <a href="https://jp.linkedin.com/in/katsuyuki-nakamura-19b9bb88">Dr. Katsuyuki Nakamura</a> and Mr. Takumi Nito. My current research focus includes machine learning, reinforcement learning, computer vision, robotics. <br> <br>

Prior to this, I graduated from <a href="https://www.iitb.ac.in/">IIT Bombay</a>, earning B.Tech in Electrical Engineering + Minor in Computer Science, and received Undergraduate Research Award 2019. I have also interned at <a href="https://research.samsung.com/sri-b">Samsung Research Institute</a> (Summer 2018). <br> <br>
Email ID: <a href="mailto: sazim@ucsd.edu">sazim@ucsd.edu</a><br><br>
<b>I am actively looking for full-time positions in industry. If you think I may be a good fit, feel free to reach out to me!</b>
</div>

<!-- To get an insight on my professional life so far, you can have a look at my [CV]({{site.url}}/cv/). I’m happy to get in touch at <a href="mailto:{{ site.email }}">{{ site.email }}</a>. -->

<!-- I was advised by [Prof. Debraj Chakraborty](https://www.ee.iitb.ac.in/wiki/faculty/dc) for my undergraduate thesis on optimal pursuer-evader shepherding problem. -->

<!-- In the summer of 2018, I had the oppurtunity to work with [Dr. Shankar M Venkatesan](https://www.linkedin.com/in/shankar-venkatesan-7a849258/) in Advanced Technology Lab at [Samsung Research Institute Bangalore](https://research.samsung.com/sri-b) on blackboard handwriting recognition using smartwatches. In 2017, I worked with Prof. [Subhasis Chaudhuri](https://www.ee.iitb.ac.in/~sc/main/main.html) in the Vision and Image Processing Lab at IIT Bombay on a beautiful and hot research topic of object recognition using Zero Shot Learning (ZSL) where we build models for recognizing unseen class objects (whose training examples the model has not seen during training).<br>

I also joined an on-campus student-driven team, [Innovation Cell](http://www.umiciitb.com/), working in Driverless Cars where I was responsible for handling the vision and machine learning aspects of the driverless car which involved detecting roads, side-lanes, obstacles etc, in different conditions of light (dark night, sunlight as well as partial shadow conditions).<br> -->

<!-- I received my undergraduate degree at [IIT Bombay](http://iitb.ac.in). In the past, I've spent some excellent summers at [Google Brain](https://research.google/teams/brain) (Summer 2020), [Google AI Language](https://ai.google/research/teams/language/) (Summer 2019), [Toyota Technological Institute at Chicago](https://www.ttic.edu/) (Summer 2017) and [Mozilla](https://www.mozilla.org/en-US/) (Summer 2016). -->

<!-- I maintain a list of my publications and research implementations under the [Research]({{ site.url }}/research) tab. To get an insight on my professional life so far, you can have a look at my [CV]({{ site.url }}/cv). I'm happy to get in touch at [kalpesh@cs.umass.edu](mailto:kalpesh@cs.umass.edu). -->

<!-- I [blog]({{ site.url }}/archive) every now and then compiling my personal experiences. Feel free to read a bit [more about me]({{ site.url }}/about)! -->

<!-- <table width="100%" align="center" border="0" cellspacing="0">
<tbody>
	<tr>
		<td>
			<heading>Updates</heading>
		</td>
	</tr>
</tbody>
</table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:15px">
<tbody>
	<tr>
		<div style="height: 180px; overflow: auto; font-size: 14px;">
			<table>
			<col width="100px">
			<col width="650px">
			<tr><td><b>Aug 2022:</b></td><td>Teaching Assistant for "ECE 225A: Probability and Statistics for Data Science" at UCSD</td></tr>
			<tr><td><b>Apr 2022:</b></td><td>Teaching Assistant for "ECE 109: Engineering Probability and Statistics" at UCSD</td></tr>
			<tr><td><b>Jan 2022:</b></td><td>Teaching Assistant for "ECE 101: Linear Systems" at UCSD</td></tr>
			<tr><td><b>Sep 2021:</b></td><td>Started my M.S. in Electrical and Computer Engineering at UC San Diego</td></tr>
			<tr><td><b>Feb 2021:</b></td><td>Presented: Localization in dynamic scenarios using SLAM at Hitachi Kenron</td></tr>
			<tr><td><b>Jul 2020:</b></td><td>Talk at Hitachi AI Conference on Indoor Positioning Systems (<a href="{{site.url}}/assets/pubs/HAIC2020_slides.pdf">slides</a>)</td></tr>
			<tr><td><b>Oct 2019:</b></td><td>Joined Intelligent Vision Research Group at <a href="https://www.hitachi.com/rd/index.html">Hitachi Central Research Lab</a> in Tokyo </td></tr>
			<tr><td><b>Sep 2019:</b></td><td><a href="https://ieeexplore.ieee.org/document/8970257">Paper</a> on Indoor Distance Estimation using LSTMs over WLAN network accepted at <a href="https://ieeexplore.ieee.org/xpl/conhome/8961320/proceeding">WPNC 2019</a></td></tr>
			<tr><td><b>Aug 2019:</b></td><td>Graduated from IIT Bombay, receiving the Undergraduate Research Award</td></tr>
			<tr><td><b>Jan 2019:</b></td><td>Teaching Assistant for Signals and Systems (EE 210) at <a href="https://www.iitb.ac.in">IIT Bombay</a></td></tr>
			<tr><td><b>Jul 2018:</b></td><td>Successfully completed internship at <a href="https://research.samsung.com/sri-b">Samsung Research Institute</a> in Bengaluru</td></tr>
			</table>
		</div>
	</tr>
</tbody>
</table> -->
<!-- ---------------------------------------------------------------------------------------------------------------------------- -->
<table width="100%" align="center" border="0" cellspacing="0" class="tableHeadings">
	<tbody>
		<tr>
			<td>
				<heading>Research Interests</heading>
			</td>
		</tr>
	</tbody>
</table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:15px">
	<tbody>
		<tr>
			<div>
				I am broadly interested in the field of <b>machine learning</b>, <b>robot learning</b> and <b>computer vision</b>, which arises from my fascination with discovering similarities between human learning and artificial intelligence. As a remarkable product of evolution, humans can serve as a blueprint for the generalization and adaptation of neural agents. My research aims to develop AI algorithms that can be implemented in real-world systems, enabling them to learn from human demonstrations and advance through self-supervised learning and curiosity. I believe AI in the future should be flexible, learn with little supervision, and learn continuously over their lifetime. I work with reinforcement learning, machine learning, computer vision and robotics.
				<!-- <br><span class="brHeight"></span> -->
				<!-- <br><span class="brHeight"></span> -->
			</div>
		</tr>
	</tbody>
</table>
<!-- ---------------------------------------------------------------------------------------------------------------------------- -->
<table width="100%" align="center" border="0" cellspacing="0" class="tableHeadings">
	<tbody>
		<tr>
			<td>
				<heading>Research Projects</heading>
			</td>
		</tr>
	</tbody>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:15px">
<tbody>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/slam_wallpaper.png'>
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<papertitle>Localization in Dynamic Environments with Targeted Inference VI-SLAM</papertitle>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<strong>Saqib Azim</strong>, Takumi Nito, <a href="https://www.linkedin.com/in/katsuyuki-nakamura-19b9bb88/?originalSubdomain=jp">Katsuyuki Nakamura</a><br>
				<em>Japan Patent Filed in Aug '21 (pending)</em>
				<br><span class="brHeight"></span>
				<a href="{{site.url}}/assets/pubs/slam_thesis.pdf">report</a> / <a href="{{site.url}}/assets/pubs/slam_review_slides.pdf">presentation</a><br>
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/lps_wallpaper.PNG'>
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<a href="https://arxiv.org/abs/2003.13991"><papertitle>Indoor Distance Estimation using LSTMs over WLAN Network</papertitle></a>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<a href="https://sabsathai.github.io/">Pranav Sankhe</a>, <strong>Saqib Azim</strong>, <a href="https://saching007.github.io/">Sachin Goyal</a>, <a href="https://www.linkedin.com/in/tanya-choudhary-772660133/">Tanya Choudhary</a>, <a href="https://www.ee.iitb.ac.in/~akumar/">Kumar Appaiah</a>, <a href="https://www.sc.iitb.ac.in/~srikant/dokuwiki/doku.php/home">Sukumar Srikant</a>
				<br>
				<em>IEEE Workshop on Positioning, Navigation and Communications (WPNC)</em>, 2019<br>
				<em>Indian Patent Filed in Dec '18 (pending)</em>
				<br><span class="brHeight"></span>
				<a href="javascript:toggleblock('lps_abs')">abstract</a> / <a href="https://arxiv.org/abs/2003.13991">arXiv</a> / <a href="https://ieeexplore.ieee.org/document/8970257">paper</a> / <a href="{{site.url}}/assets/pubs/HAIC2020_slides.pdf">presentation</a><br>
				<br><span class="brHeight"></span>
				<p id="lps_abs" class="abstract">The Global Navigation Satellite Systems (GNSS) like GPS suffer from accuracy degradation and are almost unavailable in indoor environments. Indoor positioning systems (IPS) based on WiFi signals have been gaining popularity. However, owing to the strong spatial and temporal variations of wireless communication channels in the indoor environment, the achieved accuracy of existing IPS is around several tens of centimeters. We present the detailed design and implementation of a self-adaptive WiFi-based indoor distance estimation system using LSTMs. The system is novel in its method of estimating with high accuracy the distance of an object by overcoming possible causes of channel variations and is self-adaptive to the changing environmental and surrounding conditions. The proposed design has been developed and physically realized over a WiFi network consisting of ESP8266 (NodeMCU) devices. The experiments were conducted in a real indoor environment while changing the surroundings in order to establish the adaptability of the system. We compare different architectures for this task based on LSTMs, CNNs, and fully connected networks (FCNs). We show that the LSTM based model performs better among all the above-mentioned architectures by achieving an accuracy of 5.85 cm with a confidence interval of 93% on the scale of (8.46 m × 6.98 m). To the best of our knowledge, the proposed method outperforms other methods reported in the literature by a significant margin</p>
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<a href="{{site.url}}/assets/pubs/btp_thesis.pdf" target="_blank"><img src='{{ site.url }}/assets/images/btp_wallpaper.png' alt="LPS" width="100%"></a>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<a href="{{site.url}}/assets/pubs/btp_thesis.pdf"><papertitle>Optimal Multi-Agent Pursuer-Evader Shepherding Problem</papertitle></a>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<strong>Advisor: </strong><a href="https://www.ee.iitb.ac.in/wiki/faculty/dc">Prof. Debraj Chakraborty</a>
				<br><span class="brHeight"></span>
				<a href="javascript:toggleblock('btp_thesis_abs')">abstract</a> / <a href="{{site.url}}/assets/pubs/btp_thesis.pdf">thesis</a> / <a href="{{site.url}}/assets/pubs/btp_presentation.pdf">presentation</a><br>
				<br><span class="brHeight"></span>
				<p id="btp_thesis_abs" class="abstract">In this report, we proposed an interaction rule between an evader and a pursuer and our objective was to try to find an optimal feedback control for the pursuer to drive the evaders to destination. With this regard, we first formulated our problem as a constrained optimization problem and solved using global search algorithm available in global optimization toolbox of matlab. The result from these experiments were then used to predict a feedback control algorithm but unfortunately this could not be made possible. Then we shifted from predicting ourselves to let the machine learn from the data and predict the trajectory for us. We used LSTM-based model with fully connected layers and posed the problem as a regression task to produce pursuer next position given current and past trajectory information of all the agents. The experimental results from the optimization task was used as dataset for this approach. After training, the trajectories were estimated iteratively for numerous initial conditions but we could not get the desired result. This approach requires modifications in order for it to work.</p>
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<img src='{{ site.url }}/assets/images/handwriting_recog_wallpaper.png' alt="LPS" width="100%">
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<papertitle>Handwritten Text Recognition using Smartwatch</papertitle>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				Student Research Fellow at <a href="https://research.samsung.com/sri-b">Samsung Research Institute Bengaluru</a> advised by <a href="https://www.linkedin.com/in/shankar-venkatesan-7a849258/">Dr. Shankar Venkatesan</a><br>
				<span class="brHeight"></span>
				<a href="javascript:toggleblock('hand_text_recog_abs')">abstract</a><br>
				<br><span class="brHeight"></span>
				<p id="hand_text_recog_abs" class="abstract">Prototyped a handwritten text recognizer by estimating wrist movements using smartwatch IMU sensors· Employed learned frequency filters followed by adaptive thresholding to improve raw signal SNR· Learned the relationship between hand movements (IMU signals) and character pattern using an SVM classifier (detecting valid IMU signal segments), and an LSTM (for character recognition)· Trained the end-to-end system on a custom-created dataset and achieved 87% recognition accuracy</p>
			</div>
		</td>
	</tr>
</tbody>
</table>

<table width="100%" align="center" border="0" cellspacing="0" class="tableHeadings">
	<tbody>
		<tr>
			<td>
				<heading>Academic Projects</heading>
			</td>
		</tr>
	</tbody>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:15px">
<tbody>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/adversarial_CLIP_logo.png' alt="SpeechEnhancement" width="100%">
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<papertitle>Adversarial Robustness Analysis of CLIP Model</papertitle>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<strong>Saqib Azim</strong>, <a href="https://lilyweng.github.io/">Prof. Lily Weng</a>
				<!-- <br><span class="brHeight"></span> -->
				<!-- <a href="javascript:toggleblock('speech_enhancement_abs')">abstract</a> / <a href="{{site.url}}/assets/pubs/speech_enhancement_report.pdf">report</a> / <a href="{{site.url}}/assets/pubs/speech_enhancement_slides.pdf">presentation</a><br> -->
				<!-- <br><span class="brHeight"></span> -->
				<!-- <p id="speech_enhancement_abs" class="abstract">In this project, we present an end-to-end data-driven system for enhancing the quality of speech signals using a convolutional-recurrent neural network. We present a quantitative and qualitative analysis of our speech enhancement system on a real-world noisy speech dataset and evaluate our proposed system's performance using several metrics such as SNR, PESQ, STOI, etc. We have employed wavelet pooling mechanism instead of max-pooling layer in the convolutional layer of our proposed model and compared the performances of these variants. Based on our experiments, we demonstrate that our model's performance on noisy speech signals using haar wavelet is better than when using max-pooling. In addition, wavelet based approach results in faster convergence during training as compared to other variants.</p> -->
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/speech_enhancement_wallpaper.png' alt="SpeechEnhancement" width="100%">
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<a href="{{site.url}}/assets/pubs/speech_enhancement_report.pdf"><papertitle>Speech Enhancement using Convolutional-Recurrent Network & Wavelet Pooling</papertitle></a>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				Parthasarathi Kumar, <strong>Saqib Azim</strong>
				<br><span class="brHeight"></span>
				<a href="javascript:toggleblock('speech_enhancement_abs')">abstract</a> / <a href="{{site.url}}/assets/pubs/speech_enhancement_report.pdf">report</a> / <a href="{{site.url}}/assets/pubs/speech_enhancement_slides.pdf">presentation</a><br>
				<br><span class="brHeight"></span>
				<p id="speech_enhancement_abs" class="abstract">In this project, we present an end-to-end data-driven system for enhancing the quality of speech signals using a convolutional-recurrent neural network. We present a quantitative and qualitative analysis of our speech enhancement system on a real-world noisy speech dataset and evaluate our proposed system's performance using several metrics such as SNR, PESQ, STOI, etc. We have employed wavelet pooling mechanism instead of max-pooling layer in the convolutional layer of our proposed model and compared the performances of these variants. Based on our experiments, we demonstrate that our model's performance on noisy speech signals using haar wavelet is better than when using max-pooling. In addition, wavelet based approach results in faster convergence during training as compared to other variants.</p>
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/barc_interiit_wallpaper.png' alt="EDL" width="100%">
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<a href="{{ site.url }}/assets/pubs/barc_interiit_presentation.pdf"><papertitle>TV Audience Measurement Challenge</papertitle></a>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<strong>Saqib Azim</strong>, <a href="https://sabsathai.github.io/">Pranav Sankhe</a>, <a href="https://saching007.github.io/">Sachin Goyal</a>, Sanyam Khandelwal, Tanmay Patil<br>
				<em>Bronze Medal (3<sup>rd</sup> / 23 teams), <a href="https://saqib1707.github.io/assets/pubs/problem_statement_barc.pdf">TV Audience Measurement Challenge</a>; Overall Runner-up (2<sup>nd</sup> / 23 IITs), <a href="https://www.iitb.ac.in/en/event/7th-inter-iit-tech-meet">Inter-IIT Tech Meet 2018</a></em>
				<br><span class="brHeight"></span>
				<a href="javascript:toggleblock('barc_interiit_abs')">abstract</a> / <a href="https://github.com/saqib1707/TV-Audience-Measurement">code</a> / <a href="{{ site.url }}/assets/pubs/barc_interiit_presentation.pdf">presentation</a><br>
				<br><span class="brHeight"></span>
				<p id="barc_interiit_abs" class="abstract">Proposed scalable and robust solutions for <a href="https://saqib1707.github.io/assets/pubs/problem_statement_barc.pdf">various challenges</a> put forward by <a href="https://www.barcindia.co.in/">BARC India</a> such as channel identification, advertisement and content classification and recognition, age and gender recognition of viewers and providing hardware free solution in order to capture TV viewership data of the country</p>
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/edl_wallpaper.png' alt="EDL" width="100%">
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<a href="{{site.url}}/assets/pubs/edl_report.pdf"><papertitle>PPG Signal Acquisition Module</papertitle></a>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<strong>Advisor: </strong>
				<a href="https://www.ee.iitb.ac.in/~pcpandey/">Prof. Prem C Pandey</a>
				<br>
				<strong>Saqib Azim</strong>, <a href="https://sabsathai.github.io/">Pranav Sankhe</a>, Ritik Madan
				<br><span class="brHeight"></span>
				<a href="javascript:toggleblock('edl_ppg_abs')">abstract</a> / <a href="{{site.url}}/assets/pubs/edl_report.pdf">report</a><br>
				<br><span class="brHeight"></span>
				<p id="edl_ppg_abs" class="abstract">A photoplethysmogram(PPG) is an optically obtained plethysmogram, a volumetric measurement of an organ. With each cardiac cycle the heart pumps blood to the periphery. The change in the volume caused by the blood is detected by illuminating the skin with IR light. We developed and implemented an electronic system to capture and display the PPG signal. We make infrared(IR) light incident on finger tip and measure the reflected IR light using a phototransistor which contains the PPG signal. The raw PPG signal is in the form of current output of the phototransistor, typically [0.2-0.4] mA, and we use a current to voltage converter to get the voltage signal. The raw PPG often has a large slowly varying baseline and it needs to be restored to optimally use the available ADC range. We carry out baseline restoration by controlling the bias voltage of the current injector using a microcontroller. We amplify the signal using a fixed value of gain resistor in the current to voltage converter. We also designed an auto-led intensity control to control the LED current and hence the emitted IR light in an effort to make the acquisition module adaptable to users with varying skin colours, motion artifacts etc. Finally we display the PPG signal on an android smartphone by transmitting the PPG signal over bluetooth.</p>
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/zsl_wallpaper.png' alt="EDL" width="100%">
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<papertitle>Zero-Shot Learning for Object Recognition</papertitle>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<strong>Advisor: </strong> <a href="https://www.ee.iitb.ac.in/~sc/main/main.html">Prof. Subhasis Chaudhuri</a>
				<br><span class="brHeight"></span>
				<a href="javascript:toggleblock('zsl_abs')">abstract</a> / <a href="https://github.com/saqib1707/Zero-Shot-Learning">code</a><br>
				<br><span class="brHeight"></span>
				<p id="zsl_abs" class="abstract">Proposed a semi-supervised VGG16-based encoder-decoder network to learn visual-to-semantic space mapping using novel combination of margin-based hinge-rank loss and Word2Vec embeddings. Explored multiple networks for better visual feature representations. Achieved improvement in recognition performance from 58.7% to 65.3% on the Animals with Attributes dataset over existing methods. </p>
			</div>
		</td>
	</tr>
	<tr>
		<td class="projectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/image_editor_wallpaper.png' alt="image_editor" width="100%">
			</div>
			<script type="text/javascript">
				function inerf_start() {
					document.getElementById('inerf_image').style.opacity = "1";
				}
				function inerf_stop() {
					document.getElementById('inerf_image').style.opacity = "0";
				}
				inerf_stop()
			</script>
		</td>
		<td class="projectBody">
			<a href="{{site.url}}/assets/pubs/image_editor_report.pdf"><papertitle>Image Editor Module</papertitle></a>
			<br><span class="brHeight"></span>
			<div class="authorDetails">
				<em>Course: Digital Image Processing</em>
				<br><span class="brHeight"></span>
				<a href="{{site.url}}/assets/pubs/image_editor_report.pdf">report</a> / <a href="https://github.com/saqib1707/Image-Editor">code</a>
			</div>
		</td>
	</tr>
</tbody>
</table>

<table width="100%" align="center" border="0" cellspacing="0" class="tableHeadings">
	<tbody>
		<tr>
			<td>
				<heading>Teaching and Mentoring Experience</heading>
			</td>
		</tr>
	</tbody>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:15px">
<tbody>
	<tr>
		<td class="smallprojectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/ucsd_logo.png' alt="UCSD_logo" width="100%">
			</div>
		</td>
		<td class="bigprojectBody">
			<papertitle>Graduate Teaching Assistant</papertitle>, <a href="https://jacobsschool.ucsd.edu/">UC San Diego</a><br>
			<span class="brHeight"></span>
			<div class="authorDetails">
				- DSC 140A - Probabilistic Modeling and Machine Learning (Spring 2023) by <a href="https://www.berkustun.com/">Prof. Berk Ustun</a><br>
				- CSE 166 - Image Processing (Winter 2023) by <a href="https://cseweb.ucsd.edu/~bochoa/">Prof. Ben Ochoa</a><br>
				- ECE 225A - Probability and Statistics for Data Science (Fall 2022) by <a href="https://scholar.google.com/citations?user=WUEjHB8AAAAJ&hl=en">Prof. Alon Orlitsky</a><br>
				<!-- [4] ECE 109 - Engineering Probability and Statistics (Spring 2022), taught by <a href="https://scholar.google.com/citations?user=WUEjHB8AAAAJ&hl=en">Prof. Alon Orlitsky</a><br> -->
				- ECE 101 - Linear Signals and Systems (Winter 2022) by <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=452">Prof. Saharnaz Baghdadchi</a><br>
			</div>
		</td>
	</tr>
	<tr>
		<td class="smallprojectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/iitbombay_logo.png' alt="UCSD_logo" width="100%">
			</div>
		</td>
		<td class="bigprojectBody">
			<papertitle>Teaching Assistant</papertitle>, <a href="https://www.iitb.ac.in/">IIT Bombay</a><br>
			<span class="brHeight"></span>
			<div class="authorDetails">
				EE 210 - Signals and Systems (Spring 2019) by <a href="https://www.ee.iitb.ac.in/~jayakrishnan.nair/">Prof. J.K. Nair</a>
			</div>
		</td>
	</tr>
	<tr>
		<td class="smallprojectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/nss_logo.png' alt="UCSD_logo" width="100%">
			</div>
		</td>
		<td class="bigprojectBody">
			<papertitle>Teaching Volunteer</papertitle>, <a href="https://nss.iitb.ac.in/home/">National Service Scheme, IIT Bombay</a><br>
			<span class="brHeight"></span>
			<div class="authorDetails">
				<span class="brHeight"></span>
				<p>Taught Science and Mathematics to underprivileged students under <a href="https://nss.iitb.ac.in/depts/EO/">Education Outreach Program</a> during 2015 - 16 </p>
			</div>
		</td>
	</tr>
	<tr>
	<td class="smallprojectWallpaper">
			<div>
				<img src='{{ site.url }}/assets/images/mnpclub_iitb_logo.png' alt="UCSD_logo" width="100%">
			</div>
		</td>
		<td class="bigprojectBody">
			<papertitle>Mentor</papertitle>, <a href="http://mnp-club.github.io/sos/">Summer of Science ('19 & '20), IIT Bombay</a><br>
			<span class="brHeight"></span>
			<div class="authorDetails">
			<p>Helped 2 Masters', 4 UG students to learn topics in the field of AI, machine learning, vision and image processing. Guided them through project ideation and project completion over the course of summer</p>
			</div>
		</td>
	</tr>
	<!-- <tr>
	<td class="projectBody">
		<papertitle>Mentor</papertitle>, <a href="https://www.alumni.iitb.ac.in/en/newsletter-article/2017-06/institute-technical-summer-projects-itsp-kickstart">Institute Technical Summer Project '17, IIT Bombay</a><br>
		<span class="brHeight"></span>
		<div class="authorDetails">
		<p>Guided 2 teams of UG students in building exciting and innovative ideas into working protoytpes over the course of summer</p>
		</div>
	</td>
	</tr> -->
</tbody>
</table>

<table width="100%" align="center" border="0" cellspacing="0">
<tbody>
  <tr>
    <td>
      <heading>Open Source Contribution</heading>
    </td>
  </tr>
</tbody>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:15px">
<tbody>
  <tr>
	<td class="smallprojectWallpaper">
		<div>
			<img src='{{ site.url }}/assets/images/kivy_logo.png' alt="Kivy_logo" width="100%">
		</div>
	</td>
    <td class="bigprojectBody">
      <papertitle><a href="https://kivy.org/#home"><b>Kivy</b></a>, <a href="http://kivent.org"><b>KivEnt</b></a></papertitle> - Open-source platforms for innovative UI development<br>
      <span class="brHeight"></span>
      <div class="authorDetails">
        <span class="brHeight"></span>
        <p>Contributed to several projects in open-source platforms - Kivy, Kivent. Introduced new features, solved multiple development-related bugs and issues, worked on map development for game-engine interfaces</p>
        <!-- <p>Contributed to several open source projects for Kivy. Merged 9 pull request (PR) to Kivy and 2 PR to Kivent. Introduced a new feature in Kivent to get tile index given the pixel values for orthogonal, isometric, staggered isometric and hexagonal game maps by analyzing their geometrical construction</p> -->
      </div>
    </td>
  </tr>
</tbody>
</table>